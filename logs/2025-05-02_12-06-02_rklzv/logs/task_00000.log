2025-05-02 12:06:02.132 | INFO     | datatrove.utils.logging:add_task_logger:58 - Launching pipeline for rank=0
2025-05-02 12:06:02.133 | INFO     | datatrove.utils.logging:log_pipeline:90 - 
--- 🛠️ PIPELINE 🛠
📖 - READER: 🐿 Jsonl
🔻 - FILTER: 🌍 Language ID
💽 - WRITER: 🐿 Jsonl
2025-05-02 12:06:02.160 | INFO     | datatrove.pipeline.readers.base:read_files_shard:201 - Reading input file cleaned_documents.jsonl.gz, 1/2
2025-05-02 12:06:04.277 | ERROR    | datatrove.executor.base:_run_for_rank:108 - Compression type False not supported
Traceback (most recent call last):

  File "/Users/adrienloizeau/dev/scratchGPT/data_pipeline.py", line 47, in <module>
    executor.run()
    │        └ <function LocalPipelineExecutor.run at 0x11fa73ac0>
    └ <datatrove.executor.local.LocalPipelineExecutor object at 0x11fa3cdf0>

  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/executor/local.py", line 127, in run
    stats.append(self._launch_run_for_rank(rank, ranks_q))
    │     │      │    │                    │     └ <AutoProxy[Queue] object, typeid 'Queue' at 0x11fa3f760>
    │     │      │    │                    └ 0
    │     │      │    └ <function LocalPipelineExecutor._launch_run_for_rank at 0x11fa73a30>
    │     │      └ <datatrove.executor.local.LocalPipelineExecutor object at 0x11fa3cdf0>
    │     └ <method 'append' of 'list' objects>
    └ []
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/executor/local.py", line 76, in _launch_run_for_rank
    return self._run_for_rank(rank, local_rank)
           │    │             │     └ 0
           │    │             └ 0
           │    └ <function PipelineExecutor._run_for_rank at 0x11fa73640>
           └ <datatrove.executor.local.LocalPipelineExecutor object at 0x11fa3cdf0>
> File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/executor/base.py", line 96, in _run_for_rank
    deque(pipelined_data, maxlen=0)
    │     └ <generator object DiskWriter.run at 0x11fa5f220>
    └ <class 'collections.deque'>
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py", line 180, in run
    self.write(document, rank)
    │    │     │         └ 0
    │    │     └ Document(text="What are the license/legal requirements to write a guidebook about a specific product?\nAs the title says. I'm...
    │    └ <function DiskWriter.write at 0x11f8e4e50>
    └ 💽 - WRITER: 🐿 Jsonl
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py", line 161, in write
    self._write(self.adapter(document), self.output_mg.get_file(output_filename), original_name)
    │    │      │    │       │          │    │         │        │                 └ 'cleaned_documents.jsonl'
    │    │      │    │       │          │    │         │        └ 'cleaned_documents.jsonl'
    │    │      │    │       │          │    │         └ <function OutputFileManager.get_file at 0x11f8595a0>
    │    │      │    │       │          │    └ <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
    │    │      │    │       │          └ 💽 - WRITER: 🐿 Jsonl
    │    │      │    │       └ Document(text="What are the license/legal requirements to write a guidebook about a specific product?\nAs the title says. I'm...
    │    │      │    └ <bound method DiskWriter._default_adapter of 💽 - WRITER: 🐿 Jsonl>
    │    │      └ 💽 - WRITER: 🐿 Jsonl
    │    └ <function JsonlWriter._write at 0x11f8e5090>
    └ 💽 - WRITER: 🐿 Jsonl
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/io.py", line 43, in get_file
    self._output_files[filename] = self.fs.open(filename, mode=self.mode, compression=self.compression)
    │    │             │           │    │  │    │              │    │                 │    └ False
    │    │             │           │    │  │    │              │    │                 └ <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
    │    │             │           │    │  │    │              │    └ 'wb'
    │    │             │           │    │  │    │              └ <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
    │    │             │           │    │  │    └ 'cleaned_documents.jsonl'
    │    │             │           │    │  └ <function DataFolder.open at 0x11f859cf0>
    │    │             │           │    └ DataFolder(path='/Users/adrienloizeau/dev/scratchGPT/data', fs=<fsspec.implementations.local.LocalFileSystem object at 0x11fa...
    │    │             │           └ <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
    │    │             └ 'cleaned_documents.jsonl'
    │    └ {}
    └ <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/io.py", line 236, in open
    return super().open(path, mode=mode, *args, **kwargs)
                        │          │      │       └ {'compression': False}
                        │          │      └ ()
                        │          └ 'wb'
                        └ 'cleaned_documents.jsonl'
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/fsspec/implementations/dirfs.py", line 368, in open
    return self.fs.open(
           │    │  └ <function AbstractFileSystem.open at 0x108b79120>
           │    └ <fsspec.implementations.local.LocalFileSystem object at 0x11fa3cfd0>
           └ DataFolder(path='/Users/adrienloizeau/dev/scratchGPT/data', fs=<fsspec.implementations.local.LocalFileSystem object at 0x11fa...
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/fsspec/spec.py", line 1322, in open
    compression = get_compression(path, compression)
                  │               │     └ False
                  │               └ '/Users/adrienloizeau/dev/scratchGPT/data/cleaned_documents.jsonl'
                  └ <function get_compression at 0x108b8a830>
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/fsspec/core.py", line 544, in get_compression
    raise ValueError(f"Compression type {compression} not supported")

ValueError: Compression type False not supported
