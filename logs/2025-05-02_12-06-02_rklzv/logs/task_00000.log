2025-05-02 12:06:02.132 | INFO     | datatrove.utils.logging:add_task_logger:58 - Launching pipeline for rank=0
2025-05-02 12:06:02.133 | INFO     | datatrove.utils.logging:log_pipeline:90 - 
--- ğŸ› ï¸ PIPELINE ğŸ› 
ğŸ“– - READER: ğŸ¿ Jsonl
ğŸ”» - FILTER: ğŸŒ Language ID
ğŸ’½ - WRITER: ğŸ¿ Jsonl
2025-05-02 12:06:02.160 | INFO     | datatrove.pipeline.readers.base:read_files_shard:201 - Reading input file cleaned_documents.jsonl.gz, 1/2
2025-05-02 12:06:04.277 | ERROR    | datatrove.executor.base:_run_for_rank:108 - Compression type False not supported
Traceback (most recent call last):

  File "/Users/adrienloizeau/dev/scratchGPT/data_pipeline.py", line 47, in <module>
    executor.run()
    â”‚        â”” <function LocalPipelineExecutor.run at 0x11fa73ac0>
    â”” <datatrove.executor.local.LocalPipelineExecutor object at 0x11fa3cdf0>

  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/executor/local.py", line 127, in run
    stats.append(self._launch_run_for_rank(rank, ranks_q))
    â”‚     â”‚      â”‚    â”‚                    â”‚     â”” <AutoProxy[Queue] object, typeid 'Queue' at 0x11fa3f760>
    â”‚     â”‚      â”‚    â”‚                    â”” 0
    â”‚     â”‚      â”‚    â”” <function LocalPipelineExecutor._launch_run_for_rank at 0x11fa73a30>
    â”‚     â”‚      â”” <datatrove.executor.local.LocalPipelineExecutor object at 0x11fa3cdf0>
    â”‚     â”” <method 'append' of 'list' objects>
    â”” []
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/executor/local.py", line 76, in _launch_run_for_rank
    return self._run_for_rank(rank, local_rank)
           â”‚    â”‚             â”‚     â”” 0
           â”‚    â”‚             â”” 0
           â”‚    â”” <function PipelineExecutor._run_for_rank at 0x11fa73640>
           â”” <datatrove.executor.local.LocalPipelineExecutor object at 0x11fa3cdf0>
> File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/executor/base.py", line 96, in _run_for_rank
    deque(pipelined_data, maxlen=0)
    â”‚     â”” <generator object DiskWriter.run at 0x11fa5f220>
    â”” <class 'collections.deque'>
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py", line 180, in run
    self.write(document, rank)
    â”‚    â”‚     â”‚         â”” 0
    â”‚    â”‚     â”” Document(text="What are the license/legal requirements to write a guidebook about a specific product?\nAs the title says. I'm...
    â”‚    â”” <function DiskWriter.write at 0x11f8e4e50>
    â”” ğŸ’½ - WRITER: ğŸ¿ Jsonl
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py", line 161, in write
    self._write(self.adapter(document), self.output_mg.get_file(output_filename), original_name)
    â”‚    â”‚      â”‚    â”‚       â”‚          â”‚    â”‚         â”‚        â”‚                 â”” 'cleaned_documents.jsonl'
    â”‚    â”‚      â”‚    â”‚       â”‚          â”‚    â”‚         â”‚        â”” 'cleaned_documents.jsonl'
    â”‚    â”‚      â”‚    â”‚       â”‚          â”‚    â”‚         â”” <function OutputFileManager.get_file at 0x11f8595a0>
    â”‚    â”‚      â”‚    â”‚       â”‚          â”‚    â”” <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
    â”‚    â”‚      â”‚    â”‚       â”‚          â”” ğŸ’½ - WRITER: ğŸ¿ Jsonl
    â”‚    â”‚      â”‚    â”‚       â”” Document(text="What are the license/legal requirements to write a guidebook about a specific product?\nAs the title says. I'm...
    â”‚    â”‚      â”‚    â”” <bound method DiskWriter._default_adapter of ğŸ’½ - WRITER: ğŸ¿ Jsonl>
    â”‚    â”‚      â”” ğŸ’½ - WRITER: ğŸ¿ Jsonl
    â”‚    â”” <function JsonlWriter._write at 0x11f8e5090>
    â”” ğŸ’½ - WRITER: ğŸ¿ Jsonl
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/io.py", line 43, in get_file
    self._output_files[filename] = self.fs.open(filename, mode=self.mode, compression=self.compression)
    â”‚    â”‚             â”‚           â”‚    â”‚  â”‚    â”‚              â”‚    â”‚                 â”‚    â”” False
    â”‚    â”‚             â”‚           â”‚    â”‚  â”‚    â”‚              â”‚    â”‚                 â”” <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
    â”‚    â”‚             â”‚           â”‚    â”‚  â”‚    â”‚              â”‚    â”” 'wb'
    â”‚    â”‚             â”‚           â”‚    â”‚  â”‚    â”‚              â”” <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
    â”‚    â”‚             â”‚           â”‚    â”‚  â”‚    â”” 'cleaned_documents.jsonl'
    â”‚    â”‚             â”‚           â”‚    â”‚  â”” <function DataFolder.open at 0x11f859cf0>
    â”‚    â”‚             â”‚           â”‚    â”” DataFolder(path='/Users/adrienloizeau/dev/scratchGPT/data', fs=<fsspec.implementations.local.LocalFileSystem object at 0x11fa...
    â”‚    â”‚             â”‚           â”” <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
    â”‚    â”‚             â”” 'cleaned_documents.jsonl'
    â”‚    â”” {}
    â”” <datatrove.io.OutputFileManager object at 0x11fc7c2e0>
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/datatrove/io.py", line 236, in open
    return super().open(path, mode=mode, *args, **kwargs)
                        â”‚          â”‚      â”‚       â”” {'compression': False}
                        â”‚          â”‚      â”” ()
                        â”‚          â”” 'wb'
                        â”” 'cleaned_documents.jsonl'
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/fsspec/implementations/dirfs.py", line 368, in open
    return self.fs.open(
           â”‚    â”‚  â”” <function AbstractFileSystem.open at 0x108b79120>
           â”‚    â”” <fsspec.implementations.local.LocalFileSystem object at 0x11fa3cfd0>
           â”” DataFolder(path='/Users/adrienloizeau/dev/scratchGPT/data', fs=<fsspec.implementations.local.LocalFileSystem object at 0x11fa...
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/fsspec/spec.py", line 1322, in open
    compression = get_compression(path, compression)
                  â”‚               â”‚     â”” False
                  â”‚               â”” '/Users/adrienloizeau/dev/scratchGPT/data/cleaned_documents.jsonl'
                  â”” <function get_compression at 0x108b8a830>
  File "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/fsspec/core.py", line 544, in get_compression
    raise ValueError(f"Compression type {compression} not supported")

ValueError: Compression type False not supported
