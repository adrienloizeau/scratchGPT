2025-05-02 13:51:24.712 | INFO     | datatrove.utils.logging:add_task_logger:58 - Launching pipeline for rank=0
2025-05-02 13:51:24.713 | INFO     | datatrove.utils.logging:log_pipeline:90 - 
--- 🛠️ PIPELINE 🛠
📖 - READER: 🐿 Jsonl
None: None
🔻 - FILTER: 🥇 Gopher Quality
🔻 - FILTER: 👯 Gopher Repetition
🔻 - FILTER: 🌍 Language ID
💽 - WRITER: 🐿 Jsonl
2025-05-02 13:51:24.718 | INFO     | datatrove.pipeline.readers.base:read_files_shard:201 - Reading input file cleaned_documents.jsonl, 1/2
2025-05-02 13:51:24.923 | ERROR    | datatrove.executor.base:_run_for_rank:108 - Please install `spacy` to use en word tokenizer (`pip install spacy`).
Traceback (most recent call last):

  File "/home/ubuntu/aloizeaunanogpt/scratchGPT/data_processing.py", line 64, in <module>
    executor.run()
    │        └ <function LocalPipelineExecutor.run at 0x753cdebbbac0>
    └ <datatrove.executor.local.LocalPipelineExecutor object at 0x753cdebcc820>

  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/executor/local.py", line 127, in run
    stats.append(self._launch_run_for_rank(rank, ranks_q))
    │     │      │    │                    │     └ <AutoProxy[Queue] object, typeid 'Queue' at 0x753cdebcebc0>
    │     │      │    │                    └ 0
    │     │      │    └ <function LocalPipelineExecutor._launch_run_for_rank at 0x753cdebbba30>
    │     │      └ <datatrove.executor.local.LocalPipelineExecutor object at 0x753cdebcc820>
    │     └ <method 'append' of 'list' objects>
    └ []
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/executor/local.py", line 76, in _launch_run_for_rank
    return self._run_for_rank(rank, local_rank)
           │    │             │     └ 0
           │    │             └ 0
           │    └ <function PipelineExecutor._run_for_rank at 0x753cdebbb640>
           └ <datatrove.executor.local.LocalPipelineExecutor object at 0x753cdebcc820>
> File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/executor/base.py", line 96, in _run_for_rank
    deque(pipelined_data, maxlen=0)
    │     └ <generator object DiskWriter.run at 0x753cdebab4c0>
    └ <class 'collections.deque'>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/pipeline/writers/disk_base.py", line 178, in run
    for document in data:
                    └ <generator object BaseFilter.run at 0x753cdebaadc0>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py", line 64, in run
    for batch in batched(data, self.batch_size):
                 │       │     │    └ 1
                 │       │     └ 🔻 - FILTER: 🌍 Language ID
                 │       └ <generator object BaseFilter.run at 0x753cdebab990>
                 └ <function batched at 0x753cdef001f0>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/batching.py", line 20, in batched
    while batch := list(itertools.islice(it, n)):
                        │         │      │   └ 1
                        │         │      └ <generator object BaseFilter.run at 0x753cdebab990>
                        │         └ <class 'itertools.islice'>
                        └ <module 'itertools' (built-in)>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py", line 64, in run
    for batch in batched(data, self.batch_size):
                 │       │     │    └ 1
                 │       │     └ 🔻 - FILTER: 👯 Gopher Repetition
                 │       └ <generator object BaseFilter.run at 0x753cdebab370>
                 └ <function batched at 0x753cdef001f0>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/batching.py", line 20, in batched
    while batch := list(itertools.islice(it, n)):
                        │         │      │   └ 1
                        │         │      └ <generator object BaseFilter.run at 0x753cdebab370>
                        │         └ <class 'itertools.islice'>
                        └ <module 'itertools' (built-in)>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py", line 68, in run
    batch_filter_result = self.filter_batch(batch)
                          │    │            └ [Document(text="What are the license/legal requirements to write a guidebook about a specific product?\nAs the title says. I'...
                          │    └ <function BaseFilter.filter_batch at 0x753cdef01ab0>
                          └ 🔻 - FILTER: 🥇 Gopher Quality
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/base_filter.py", line 60, in filter_batch
    return list(map(self.filter, batch))
                    │    │       └ [Document(text="What are the license/legal requirements to write a guidebook about a specific product?\nAs the title says. I'...
                    │    └ <function GopherQualityFilter.filter at 0x753cdeb21a20>
                    └ 🔻 - FILTER: 🥇 Gopher Quality
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/pipeline/filters/gopher_quality_filter.py", line 72, in filter
    words = split_into_words(text, self.language)
            │                │     │    └ 'eng'
            │                │     └ 🔻 - FILTER: 🥇 Gopher Quality
            │                └ "What are the license/legal requirements to write a guidebook about a specific product?\nAs the title says. I'm writing guide...
            └ <function split_into_words at 0x753cdeb209d0>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/text.py", line 309, in split_into_words
    return split_into_parts(text, mode=SPLIT_TEXT_WORDS, language=language)
           │                │          │                          └ 'eng'
           │                │          └ 'WORDS'
           │                └ "What are the license/legal requirements to write a guidebook about a specific product?\nAs the title says. I'm writing guide...
           └ <functools._lru_cache_wrapper object at 0x753cdefbada0>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/text.py", line 287, in split_into_parts
    tokenizer = load_word_tokenizer(language)
                │                   └ 'eng'
                └ <functools._lru_cache_wrapper object at 0x753cdeb5d590>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/word_tokenizers.py", line 489, in load_word_tokenizer
    return word_tokenizer_factories[language_or_tok]()
           │                        └ 'eng'
           └ {'aai_Latn': functools.partial(<function load_tokenizer_assignments.<locals>.tok_factory_wrapper at 0x753cde3452d0>, 'SpaCyTo...
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/word_tokenizers.py", line 442, in tok_factory_wrapper
    return tok_class(arg)
           │         └ 'en'
           └ <class 'datatrove.utils.word_tokenizers.SpaCyTokenizer'>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/word_tokenizers.py", line 109, in __init__
    check_required_dependencies(f"{language} word tokenizer", ["spacy"])
    └ <function check_required_dependencies at 0x753cdf353490>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/_import_utils.py", line 33, in check_required_dependencies
    _raise_error_for_missing_dependencies(step_name, missing_dependencies)
    │                                     │          └ {'spacy': 'spacy'}
    │                                     └ 'en word tokenizer'
    └ <function _raise_error_for_missing_dependencies at 0x753cdf353520>
  File "/home/ubuntu/.local/lib/python3.10/site-packages/datatrove/utils/_import_utils.py", line 54, in _raise_error_for_missing_dependencies
    raise ImportError(

ImportError: Please install `spacy` to use en word tokenizer (`pip install spacy`).
