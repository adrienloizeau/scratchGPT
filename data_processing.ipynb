{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49fe530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrienloizeau/opt/anaconda3/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"jonathanli/law-stack-exchange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515feb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why TVs / laptops etc. do not warn about too brirght screen whereas many smartphones warn about too '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = [\"train\", \"test\", \"validation\"]\n",
    "\n",
    "full_dataset = \"\"\n",
    "for s in split:  \n",
    "    for i in range(len(ds[s][\"title\"])):  \n",
    "        title = ds[s][\"title\"][i]\n",
    "        body = ds[s][\"body\"][i]\n",
    "        full_dataset += title + \"\\n\" + body + \"\\n\\n\" \n",
    "\n",
    "full_dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ded5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ £§©®´·¸ßàäçèéêöüıł  ​–—‘’“”•… €₹™⇒≠ﬀ\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(full_dataset)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe3b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ £§´·¸ßàäçèéêöüıł  ​–—‘’“”• €≠ﬀ\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "unecessary_chars  = [\"©\",\"®\",\"₹\",\"™\",\"–—\",\"⇒\", \"…\"]\n",
    "filtered_dataset  = full_dataset\n",
    "for u in unecessary_chars:\n",
    "    filtered_dataset = filtered_dataset.replace(u,\"\")\n",
    "\n",
    "chars = sorted(list(set(filtered_dataset)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)\n",
    "\n",
    "dataset = filtered_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1b7cc",
   "metadata": {},
   "source": [
    "Tokenise my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb299304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why TVs / \n",
      "[57, 74, 91, 2, 54, 56, 85, 2, 17, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Why TVs / '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_dict = { c:i for i,c in enumerate(chars)}\n",
    "decode_dict = { i:c for i,c in enumerate(chars)}\n",
    "\n",
    "\n",
    "encode = lambda x: [encode_dict[c] for c in x]\n",
    "decode = lambda y: ''.join([decode_dict[c] for c in y])\n",
    "\n",
    "encoded_data = encode(dataset[:10])\n",
    "\n",
    "print(dataset[:10])\n",
    "print(encoded_data)\n",
    "decode(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86cfc753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tokenizers import Tokenizer, models, trainers\n",
    "# from tokenizers.pre_tokenizers import Whitespace\n",
    "# tokenizer.pre_tokenizer = Whitespace()\n",
    "# tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "# trainer = trainers.BpeTrainer(vocab_size=256)\n",
    "\n",
    "# tokenizer.train_from_iterator([dataset], trainer=trainer)\n",
    "# tokenizer.save(\"custom_tokenizer.json\")  # Save\n",
    "# tokenizer = Tokenizer.from_file(\"custom_tokenizer.json\")  # Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c139638",
   "metadata": {},
   "source": [
    "Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f69cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context -  \n",
      "to predict -  h\n",
      "context -  W\n",
      "to predict -  y\n",
      "context -  Wh\n",
      "to predict -   \n",
      "context -  Why\n",
      "to predict -  T\n",
      "context -  Why \n",
      "to predict -  V\n",
      "context -  Why T\n",
      "to predict -  s\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "# basic structure\n",
    "for i in range(len(dataset[:5])+1):\n",
    "    time.sleep(1)\n",
    "    print(\"context - \", dataset[:i])\n",
    "    print(\"to predict - \", dataset[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88e5aebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context -  [57]\n",
      "to predict -  74\n",
      "context -  [57, 74]\n",
      "to predict -  91\n",
      "context -  [57, 74, 91]\n",
      "to predict -  2\n",
      "context -  [57, 74, 91, 2]\n",
      "to predict -  54\n",
      "context -  [57, 74, 91, 2, 54]\n",
      "to predict -  56\n",
      "context -  [57, 74, 91, 2, 54, 56]\n",
      "to predict -  85\n",
      "context -  [57, 74, 91, 2, 54, 56, 85]\n",
      "to predict -  2\n",
      "context -  [57, 74, 91, 2, 54, 56, 85, 2]\n",
      "to predict -  17\n"
     ]
    }
   ],
   "source": [
    "# block size introduction\n",
    "block_size = 8 \n",
    "\n",
    "x = encode(dataset[:block_size]) # context\n",
    "y =  encode(dataset[1:block_size +1]) # to predict\n",
    "for t in range(block_size):\n",
    "    time.sleep(0.5)\n",
    "    print(\"context - \", x[:t+1])\n",
    "    print(\"to predict - \", y[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd38c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[75, 80,  2, 53, 83, 87, 67, 84],\n",
      "        [88, 81, 75, 70, 17, 84, 71, 85],\n",
      "        [ 2,  1,  1,  1, 54, 74, 75, 85],\n",
      "        [81, 73, 71, 80, 71, 84,  2, 38]]), tensor([71, 69,  2, 67]))\n"
     ]
    }
   ],
   "source": [
    "# adding batch dimensions\n",
    "\n",
    "import torch \n",
    "import random\n",
    "\n",
    "batch_size = 4 # number of data loaded in parallel\n",
    "block_size = 8\n",
    "\n",
    "def get_batch_v1():\n",
    "    data = torch.tensor(encode(dataset))\n",
    "    idx = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i-block_size: i] for i in idx])\n",
    "    y = torch.stack([data[i] for i in idx])\n",
    "    return x, y\n",
    "for i in range(1):\n",
    "    print(get_batch())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1f826",
   "metadata": {},
   "source": [
    "Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28468f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 74, 91, 2, 54, 56, 85, 2, 17, 2, 78, 67, 82, 86, 81, 82, 85, 2, 71, 86]\n",
      "Why TVs / laptops et\n"
     ]
    }
   ],
   "source": [
    "# data split \n",
    "split = int(len(dataset)*0.9)\n",
    "data_train = encode(dataset[:split]) # 90% of the dataset used for training\n",
    "data_val = encode(dataset[split:]) # 10% for validation\n",
    "\n",
    "print(data_train[:20])\n",
    "print(decode(data_train[:20]))\n",
    "\n",
    "data_train = torch.tensor(data_train)\n",
    "data_val = torch.tensor(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf50c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[71, 79, 67, 84, 77,  2, 81, 72],\n",
      "        [82, 78, 81, 91, 79, 71, 80, 86],\n",
      "        [79, 67, 86, 75, 81, 80,  2, 86],\n",
      "        [75, 69, 71, 80, 85, 75, 80, 73]]), tensor([ 2, 33, 81, 14]))\n"
     ]
    }
   ],
   "source": [
    "# Adding split \n",
    "\n",
    "import torch \n",
    "import random\n",
    "\n",
    "batch_size = 4 # number of data loaded in parallel\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = data_train if split == \"train\" else data_val\n",
    "    idx = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i-block_size: i] for i in idx])\n",
    "    y = torch.stack([data[i] for i in idx])\n",
    "    return x, y\n",
    "\n",
    "for i in range(1):\n",
    "    print(get_batch(\"train\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
